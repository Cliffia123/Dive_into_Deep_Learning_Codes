{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6be91c5-3813-4244-82e5-24e6114d69c8",
   "metadata": {},
   "source": [
    "# 导数和微分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b89db91-3412-4c95-9d39-6bdeb056fd96",
   "metadata": {},
   "source": [
    "## 1.几个简单的例子\n",
    "\n",
    "**导数***\n",
    "\n",
    "(1) 生成数据x，令 requires_grad=True\n",
    "\n",
    "(2) 建立 x 与 y的关系\n",
    "\n",
    "(3) 求解导数 backward()\n",
    "\n",
    "(4) reset 梯度 x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73ba093c-16cb-4096-aa5b-db712a5f5be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f85c95ff-5e5b-48c4-af5a-aee3548fa0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.], requires_grad=True), None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# requires_grad:是否需要计算梯度并保留\n",
    "x = torch.arange(4.0, requires_grad=True)\n",
    "x, x.grad #默认梯度为 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82aec72b-cabf-4250-8253-6c3424d00ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 2 * torch.dot(x, x) # y=2*x的平方, y是一个具体的数值\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37d0388f-d938-4b41-94dc-45628d4f1a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad #导数相当于 y = 4x，带入tensor([0., 1., 2., 3.]验证\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea7d490-4353-49cf-a052-66299b4408e0",
   "metadata": {},
   "source": [
    "## 2. 非标量的反向传播 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1bf385b4-8253-4bee-95f0-e852aabe1aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#在深度学习中，有时候y是矩阵，而不是一个数字，此时需要y.sum()成一个数值\n",
    "x.grad.zero_()\n",
    "y = x * x\n",
    "y.sum().backward() #或者 y.backward(gradient=torch.ones(len(y)))\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d6bc6-2865-481a-933b-b10b12d31944",
   "metadata": {},
   "source": [
    "## 3. detach 计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e596e3d0-e4ba-4139-a451-14186bc10baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.], requires_grad=True),\n",
       " tensor([0., 1., 4., 9.], grad_fn=<MulBackward0>),\n",
       " tensor([0., 1., 4., 9.]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "引入变量保留不需要计算梯度的中间项，假设我们有 z = x * y 和 y = x * x，但我们希望关注 x 对 z 的直接影响\n",
    "而不是通过 y 传递的影响。 在这种情况下，我们可以创建一个新变量 u，它的值与 y 相同，\n",
    "但它的出处（它是如何创建的）已被删除。 因此 u 在图中没有祖先，并且梯度不会通过 u 流向 x。\n",
    "例如，采用 z = x * u 的梯度将产生结果 x\n",
    "'''\n",
    "x.grad.zero_()\n",
    "y = x * x\n",
    "u = y.detach() # u 复制 y 的值，但 u 不保存梯度\n",
    "z = u * x\n",
    "z.sum().backward()\n",
    "x, y, x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2ba36ef9-2e7f-43b9-8879-0b6166558187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "虽然此过程将 y 的祖先从通向 z 的图中分离，但通向 y 的计算图仍然存在，因此我们可以计算 y 相对于 x 的梯度。\n",
    "'''\n",
    "x.grad.zero_()\n",
    "y.sum().backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf17f8-831e-4bf8-bb75-6c0e295c5a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
